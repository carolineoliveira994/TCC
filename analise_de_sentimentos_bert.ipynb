{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNf2Bd7bapFYWwdi/UkRDgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolineoliveira994/TCC/blob/main/analise_de_sentimentos_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KIU4C5hNWtRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install python-dotenv\n",
        "!pip install spacy textblob\n",
        "!python -m textblob.download_corpora\n",
        "!python -m spacy download pt_core_news_sm  # Modelo em português\n",
        "!pip install unidecode\n",
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install pandas\n",
        "!pip install unidecode nltk spacy\n",
        "!python -m spacy download pt_core_news_sm\n"
      ],
      "metadata": {
        "id": "iIRcujxg6Ttu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from dotenv import load_dotenv\n",
        "import spacy\n",
        "import re\n",
        "import unidecode\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import SnowballStemmer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "\n",
        "from google.colab import files, auth\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "print(\"Diretório atual:\", os.getcwd())"
      ],
      "metadata": {
        "id": "jJUnZI496N5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvkMFiP3vAsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coleta de dados usando a API da Bluesky\n",
        "\n",
        "\n",
        "**Objetivo**: Obter dados relevantes de postagens, comentários e interações na rede social Bluesky, focando em sentimentos relacionados às eleições de 2024.\n",
        "\n",
        "**Fontes de Dados**: Bluesky.\n",
        "\n",
        "**Técnicas de Coleta:** API do ATProtocol para interagir com os servidores Bluesky.\n",
        "\n",
        "**Autenticação**: Realizar a autenticação necessária para acessar a API, salvar credenciais no arquito .env.\n",
        "\n",
        "**Requisições HTTP:** Endpoints específicos da API que permitem obter postagens, comentários e perfis de usuários.\n",
        "\n",
        "PALAVRAS CHAVES: ELEIÇÕES, CANDITADOS, BOULOS, TABATA, DATENA...\n",
        "\n",
        "**Período de Coleta**: JUNHO.\n"
      ],
      "metadata": {
        "id": "5MlaxnCfs3Ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nrkdzu6FrdZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Packages:"
      ],
      "metadata": {
        "id": "sWiE_VsXvJp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrTiJrTIbOKJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import files, auth\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JX8HyCgDvolW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('.env', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "BLUESKY_APP_USER = 'cocorolini.bsky.social'\n",
        "BLUESKY_APP_PASS='3ovj-gbnh-trwd-k66r'\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "zs6iabB95QHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca no BLUESKY com a palavra chave \"ELEIÇÕES\""
      ],
      "metadata": {
        "id": "LJkfVJ5rwFGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py search QUAEST --sort latest --limit 100\n"
      ],
      "metadata": {
        "id": "1pHULWJI5TTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lista completa com os nomes dos arquivos CSV\n",
        "arquivos = ['/content/data/search_results_CNN_2024_10_01.csv', 'content/data/search_results_QUAEST_2024_10_01.csv', 'content/data/search_results_DETENA_2024_10_01.csv', 'content/data/search_results_PRTB_2024_10_01.csv', 'content/data/search_results_EDUCAÇÃO_2024_10_01.csv', 'content/data/search_results_SAÚDE_2024_10_01.csv', 'content/data/search_results_DEBATE_2024_10_01.csv', 'content/data/search_results_COMICIO_2024_10_01.csv', 'content/data/search_results_IPEC_2024_10_01.csv', 'content/data/search_results_NEXUS_2024_10_01.csv', 'content/data/search_results_VOTAÇÃO_2024_10_01.csv', 'content/data/search_results_NEOLIBERAL_2024_10_01.csv', 'content/data/search_results_PREFEITA_2024_10_01.csv', 'content/data/search_results_PSOL_2024_10_01.csv', 'content/data/search_results_ESQUERDA_2024_10_01.csv', 'content/data/search_results_voto_2024_10_01.csv', 'content/data/search_results_PREFEITO_2024_10_01.csv', 'content/data/search_results_SOCIALISMO_2024_10_01.csv', 'content/data/search_results_TABATA_2024_10_01.csv', 'content/data/search_results_São_Paulo_2024_10_01.csv', 'content/data/search_results_NUNES_2024_10_01.csv', 'content/data/search_results_MDB_2024_10_01.csv', 'content/data/search_results_JORNAL_2024_10_01.csv', 'content/data/search_results_PSDB_2024_10_01.csv', 'content/data/search_results_PREFEITURA_2024_10_01.csv', 'content/data/search_results_ELEITORAL_2024_10_01.csv', 'content/data/search_results_SP_2024_10_01.csv', 'content/data/search_results_VENDER_2024_10_01.csv', 'content/data/search_results_MARÇAL_2024_10_01.csv', 'content/data/search_results_DIREITA_2024_10_01.csv', 'content/data/search_results_SAO_PAULO_2024_10_01.csv','/content/data/search_results_DETENA_2024_10_01.csv','/content/data/search_results_DETENA_2024_10_01.csv','/content/data/search_results_DEBATE_2024_10_01.csv','/content/data/search_results_COMICIO_2024_10_01.csv','/content/data/search_results_CNN_2024_10_01.csv','./data/search_results_VENCER_2024_10_01.csv','./data/search_results_ELEITORAL_2024_10_01.csv','./data/search_results_COMICIO_2024_10_01.csv','./data/search_results_NEOLIBERALISMO_2024_10_01.csv','./data/search_results_SOCIALISMO_2024_10_01.csv','./data/search_results_DIREITA_2024_10_01.csv','./data/search_results_ESQUERDA_2024_10_01.csv','search_results_nunes_2024_09_29 (1).csv', 'search_results_eleicoes_2024_09_29.csv', 'search_results_candidato_2024_09_29 (1).csv', 'search_results_DATENA_2024_10_01.csv', 'search_results_PRTB_2024_10_01.csv', 'search_results_datena_2024_09_29 (2).csv', 'search_results_CANDIDATO_2024_09_29.csv', 'search_results_DATENA_2024_09_29.csv', 'search_results_CANDIDATA_2024_10_01.csv', 'search_results_VOTAR_2024_10_01.csv', 'search_results_MARÇAL_2024_09_29.csv', 'search_results_prefeito_2024_09_29.csv', 'search_results_votar_2024_10_01.csv', 'search_results_DEBATE_2024_10_01.csv', 'search_results_BOULOS_2024_09_29 (1).csv', 'search_results_economia_2024_10_01.csv', 'search_results_voto_2024_09_29.csv', 'search_results_educação_2024_10_01.csv', 'search_results_PREFEITA_2024_10_01.csv', 'search_results_PSOL_2024_10_01.csv', 'search_results_CAMPANHA_2024_10_01.csv', 'search_results_VOTO_2024_10_01.csv', 'search_results_Marçal_2024_09_29 (1).csv', 'search_results_NUNES_2024_09_29.csv', 'search_results_CAMPANHA_2024_09_29.csv', 'search_results_ELEIÇÕES_2024_09_29.csv', 'search_results_entrevista_2024_09_29.csv', 'search_results_ELEGER_2024_10_01.csv', 'search_results_Datena_2024_09_29 (1).csv', 'search_results_Política_2024_09_29.csv', 'search_results_comício_2024_09_29.csv', 'search_results_PREFEITO_2024_10_01.csv', 'search_results_TABATA_2024_10_01.csv', 'search_results_CANDIDATO_2024_10_01.csv', 'search_results_urna_2024_09_29.csv', 'search_results_saúde_2024_10_01.csv', 'search_results_ELEIÇÕES_2024_10_01.csv', 'search_results_NUNES_2024_10_01.csv', 'search_results_MDB_2024_10_01.csv', 'search_results_tabata_2024_09_29.csv', 'search_results_Boulos_2024_09_29.csv', 'search_results_marçal_2024_09_29 (2).csv', 'search_results_MARÇAL_2024_10_01.csv', 'search_results_BOULOS_2024_10_01.csv']\n",
        "\n",
        "\n",
        "# Lista para armazenar os DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Ler cada arquivo CSV e adicionar à lista de DataFrames\n",
        "for arquivo in arquivos:\n",
        "    try:\n",
        "        df = pd.read_csv(arquivo)  # Use pd.read_csv() para arquivos CSV\n",
        "        dataframes.append(df)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Arquivo {arquivo} não encontrado.\")\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"Arquivo {arquivo} está vazio.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao ler o arquivo {arquivo}: {e}\")\n",
        "\n",
        "# Verificar se a lista de DataFrames não está vazia\n",
        "if dataframes:\n",
        "    # Concatenar todos os DataFrames em um único DataFrame\n",
        "    df_concatenado = pd.concat(dataframes, ignore_index=True)\n",
        "    # Visualizar o DataFrame final\n",
        "    print(df_concatenado)\n",
        "else:\n",
        "    print(\"Nenhum DataFrame foi carregado.\")\n"
      ],
      "metadata": {
        "id": "7T1KjfpCkmwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content/data'))"
      ],
      "metadata": {
        "id": "R3UY1UGnkMqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cria** DataFrame"
      ],
      "metadata": {
        "id": "J3vrlGg-wIEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lista DataFrame criados"
      ],
      "metadata": {
        "id": "aJTVuhxAwMsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado.head())\n"
      ],
      "metadata": {
        "id": "ctueJ38PLfpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado.info())\n"
      ],
      "metadata": {
        "id": "sO_baVGKLhqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado.describe())\n"
      ],
      "metadata": {
        "id": "QczSjAPILklb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado.isnull().sum())\n"
      ],
      "metadata": {
        "id": "rG2Wm7m7Lll7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_names = [name for name, obj in globals().items() if isinstance(obj, pd.DataFrame)]\n",
        "print(dataframe_names)"
      ],
      "metadata": {
        "id": "XIwurn5p66NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Junta os DataFrames\n",
        "\n"
      ],
      "metadata": {
        "id": "XGhfGpuSwRYA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_W3UT2WGIwie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenado"
      ],
      "metadata": {
        "id": "ukIr_XUFHkMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remover colunas não ultilizadas"
      ],
      "metadata": {
        "id": "N3dnOmzkwfcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\"reply_count\", \"author_display_name\", \"author_handle\", \"indexed_at\", \"cid\", \"uri\", \"repost_count\", \"like_count\"]\n",
        "df_concatenado = df_concatenado.drop(columns=columns_to_remove)\n",
        "\n",
        "print(\"\\nDepois:\")\n",
        "print(df_concatenado)\n"
      ],
      "metadata": {
        "id": "cKAa0Sv9JgES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limpeza"
      ],
      "metadata": {
        "id": "vc6D1jhMJ4EM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpeza: Remoção de stop words: Palavras comuns que não adicionam significado (ex: \"a\", \"o\", \"de\").\n",
        "Remoção de pontuação: Pontuação pode interferir na análise.\n",
        "Remoção de números: Se não forem relevantes para a análise de sentimentos.\n",
        "Correção de erros de digitação: Utilizando técnicas de correção ortográfica."
      ],
      "metadata": {
        "id": "-1_kWvYvKgtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autenticação hugg****ntirar"
      ],
      "metadata": {
        "id": "AVIYDADkwk10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "os.environ['HF_TOKEN'] = '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'\n"
      ],
      "metadata": {
        "id": "pZ-eMcvDP2bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar o BERT para análise de sentimentos com três rótulos (positivo, negativo e neutro)"
      ],
      "metadata": {
        "id": "imnbIZ1-wunc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=3)\n"
      ],
      "metadata": {
        "id": "n0W6A385NkOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fluxo de Pré-processamento com spaCy\n",
        "\n",
        "* Remoção de URLs.\n",
        "* Remoção de menções.\n",
        "* Remoção de hashtags.\n",
        "* Remoção de números.\n",
        "* Remoção de acentos.\n",
        "* Conversão para minúsculas\n",
        "* Lematização e remoção de stop words e pontuação: Usa o spaCy para remover stop words e pontuação e retorna o texto lematizado.\n"
      ],
      "metadata": {
        "id": "1hyGhaLFxfGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"  # Retorna uma string vazia se o texto não for string\n",
        "\n",
        "    # Remover URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remover menções (@username)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Remover hashtags (#hashtag)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    # Remover números\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remover acentos\n",
        "    text = unidecode.unidecode(text)\n",
        "\n",
        "    # Converter para minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Processar o texto com spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Remover stop words e pontuação\n",
        "    cleaned_text = ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "texts = df_concatenado['text'].tolist()\n",
        "cleaned_texts = [clean_text(text) for text in texts]\n",
        "\n",
        "df_concatenado['cleaned_text'] = cleaned_texts\n",
        "print(df_concatenado[['text', 'cleaned_text']].head())\n"
      ],
      "metadata": {
        "id": "pi06AHArKjVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicar a função para rotular automaticamente os textos"
      ],
      "metadata": {
        "id": "SwLKDv59yHBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribuição de Comprimento de Textos"
      ],
      "metadata": {
        "id": "jLrychjJID1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição das listas de palavras-chave (Features)"
      ],
      "metadata": {
        "id": "-pgEL10CyuyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Carregar a coluna 'cleaned_text' do DataFrame\n",
        "data = df_concatenado['cleaned_text']\n",
        "df_concatenado = pd.DataFrame(data)\n",
        "\n",
        "# Carregar o pipeline de análise de sentimentos com modelo pré-treinado\n",
        "sentiment_pipeline = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "# Mapeamento dos rótulos para categorias\n",
        "label_mapping = {\n",
        "    '1 star': 'negativo',\n",
        "    '2 stars': 'negativo',\n",
        "    '3 stars': 'neutro',\n",
        "    '4 stars': 'positivo',\n",
        "    '5 stars': 'positivo'\n",
        "}\n",
        "\n",
        "# Classificar sentimentos e mapear para os rótulos desejados\n",
        "df_concatenado['sentiment'] = df_concatenado['cleaned_text'].apply(lambda x: label_mapping[sentiment_pipeline(x)[0]['label']])\n",
        "\n",
        "# Visualizar o DataFrame com os rótulos\n",
        "print(df_concatenado)\n"
      ],
      "metadata": {
        "id": "GBemsIl6Hh-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenado.shape"
      ],
      "metadata": {
        "id": "jlK4qJfbQlnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "_kWOUbBaKeAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Combinar todos os textos da coluna 'cleaned_text' em uma única string\n",
        "text = ' '.join(df['cleaned_text'])\n",
        "\n",
        "# Gerar a nuvem de palavras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "# Exibir a nuvem de palavras\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')  # Desativar os eixos\n",
        "plt.title('Nuvem de Palavras')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EU55cc0FKAMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenado"
      ],
      "metadata": {
        "id": "8NBvkvPtL-5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split da biblioteca sklearn é utilizada para dividir os dados em duas partes, uma para treinamento do modelo e outra para avaliação teste\n",
        "\n",
        "mportância da Divisão Estratificada:\n",
        "Como você está lidando com um problema de análise de sentimentos com três rótulos (positivo, negativo, neutro), é importante garantir que o modelo veja uma proporção representativa de cada classe durante o treinamento e também durante a avaliação. Isso é especialmente relevante quando as classes são desbalanceadas, como no seu caso (com muito mais instâncias positivas do que negativas e neutras).\n",
        "\n",
        "Exemplo Prático:\n",
        "Se você tem um total de 2641 instâncias no DataFrame df_concatenado, a divisão estratificada irá garantir algo como:\n",
        "\n",
        "Treinamento: Aproximadamente 2112 instâncias (80% do total), distribuídas de maneira proporcional aos rótulos.\n",
        "Avaliação: Aproximadamente 529 instâncias (20% do total), também com a mesma distribuição proporcional."
      ],
      "metadata": {
        "id": "LMwOkQXxzsb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, eval_df = train_test_split(df_concatenado, test_size=0.2, random_state=42, stratify=df_concatenado['sentiment'])\n",
        "\n",
        "print(\"Dados de Treinamento:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nDados de Avaliação:\")\n",
        "print(eval_df.head())\n"
      ],
      "metadata": {
        "id": "JtrshX7zaZ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a contagem de exemplos por classe\n",
        "print(df_concatenado['sentiment'].value_counts())\n"
      ],
      "metadata": {
        "id": "VyGsbyUHDkR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_concatenado['sentiment'].value_counts())\n"
      ],
      "metadata": {
        "id": "6iRTqTN7a2yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizar os textos usando o BERT em português\n",
        "\n",
        "**input_ids**: IDs numéricos correspondentes aos tokens do texto.\n",
        "\n",
        "**attention_mask**: Máscara de atenção que indica quais tokens são reais e quais são padding (zeros)."
      ],
      "metadata": {
        "id": "cudGJiMt01ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Carregar o tokenizer do modelo pré-treinado em português\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Função para tokenizar os textos\n",
        "def tokenize_function(texts):\n",
        "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "# Tokenizar os dados de treinamento e de avaliação\n",
        "train_encodings = tokenize_function(train_df['cleaned_text'].tolist())\n",
        "eval_encodings = tokenize_function(eval_df['cleaned_text'].tolist())\n",
        "\n",
        "# Exibir a estrutura dos encodings gerados\n",
        "print(train_encodings.keys())  # Mostra as chaves, como 'input_ids', 'attention_mask'\n",
        "print(eval_encodings.keys())\n"
      ],
      "metadata": {
        "id": "a4TCF2JpgX_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste"
      ],
      "metadata": {
        "id": "D8JkT0jVViyU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftYfksDSncLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir o SentimentDataset e os loaders de dados de treinamento e avaliação.\n",
        "\n",
        "**SentimentDataset**: organiza os dados de entrada (codificações e rótulos) para que possam ser usados pelo modelo.\n",
        "\n",
        "**DataLoader**: facilita o carregamento dos dados em lotes para alimentar o modelo durante o treinamento e a avaliação."
      ],
      "metadata": {
        "id": "Q6Oa8hOR1W9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SentimentAnalysisDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Usar .clone().detach() para evitar o aviso\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "\n",
        "        # Garantir que os rótulos estejam no formato correto\n",
        "        item['sentiment'] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Mapear os rótulos para números usando o mapeamento\n",
        "label_mapping = {\"positivo\": 2, \"neutro\": 1, \"negativo\": 0}\n",
        "train_labels = [label_mapping[label] for label in train_df['sentiment']]\n",
        "eval_labels = [label_mapping[label] for label in eval_df['sentiment']]\n",
        "\n",
        "# Criar os datasets para treinamento e avaliação\n",
        "train_dataset = SentimentAnalysisDataset(train_encodings, train_labels)\n",
        "eval_dataset = SentimentAnalysisDataset(eval_encodings, eval_labels)\n"
      ],
      "metadata": {
        "id": "seVXyhnegaz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Carregar o modelo BERT para classificação com 3 rótulos (positivo, neutro, negativo)\n",
        "model = BertForSequenceClassification.from_pretrained('neuralmind/bert-large-portuguese-cased', num_labels=3)\n"
      ],
      "metadata": {
        "id": "L2no0EGWIYhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJvv1AAhffXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir o otimizador (usando Adam, mas pode ser alterado para outro otimizador)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)  # lr = taxa de aprendizado (learning rate)\n",
        "\n",
        "# Definir a função de perda (loss function)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()  # Como você tem rótulos categóricos (positivo, neutro, negativo), CrossEntropyLoss é adequada"
      ],
      "metadata": {
        "id": "XcayHb1me__p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qISiT8-kkhjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import precision_recall_fscore_support, precision_recall_curve, average_precision_score\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "\n",
        "# Definir dispositivo (GPU se disponível, caso contrário CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Utilizando:\", device)\n",
        "\n",
        "# Defina o número de classes\n",
        "num_classes = 3  # Ajuste conforme necessário\n",
        "\n",
        "model.to(device)  # Mover o modelo para o dispositivo\n",
        "\n",
        "# Inicialize o otimizador\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Defina a função de perda\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Defina o número de épocas\n",
        "num_epochs = 5  # Defina o número de épocas que você deseja treinar\n",
        "\n",
        "# Inicialize listas para armazenar as métricas\n",
        "train_precisions = []\n",
        "val_precisions = []\n",
        "\n",
        "train_recalls = []\n",
        "val_recalls = []\n",
        "\n",
        "train_f1s = []\n",
        "val_f1s = []\n",
        "\n",
        "# Crie DataLoader para os datasets de treinamento e validação\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # Ajuste o tamanho do lote conforme necessário\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=16)  # Ajuste o tamanho do lote conforme necessário\n",
        "\n",
        "# Loop de treinamento\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Treinamento\n",
        "    model.train()\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "    train_loss_total = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()  # Zera os gradientes\n",
        "\n",
        "        # Mover os tensores de entrada e rótulos para o dispositivo\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['sentiment'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "        loss.backward()  # Calcula os gradientes\n",
        "        optimizer.step()  # Atualiza os pesos\n",
        "\n",
        "        # Acumular a perda total\n",
        "        train_loss_total += loss.item()\n",
        "\n",
        "        # Obter predições\n",
        "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "        train_preds.extend(preds)\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calcular precisão, recall e f1-score no conjunto de treino\n",
        "    train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(train_labels, train_preds, average='weighted')\n",
        "    train_precisions.append(train_precision)\n",
        "    train_recalls.append(train_recall)\n",
        "    train_f1s.append(train_f1)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss_total/len(train_loader):.4f}\")\n",
        "    print(f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train F1: {train_f1:.4f}\")\n",
        "\n",
        "    # Avaliação\n",
        "    model.eval()\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    val_probabilities = []\n",
        "\n",
        "    with torch.no_grad():  # Desativa o cálculo de gradientes\n",
        "        for batch in eval_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['sentiment'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "            probabilities = torch.softmax(outputs.logits, dim=1).cpu().numpy()  # Probabilidades para todas as classes\n",
        "\n",
        "            val_preds.extend(preds)\n",
        "            val_probabilities.extend(probabilities)\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calcular precisão, recall e f1-score no conjunto de validação\n",
        "    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='weighted')\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    val_f1s.append(val_f1)\n",
        "\n",
        "    print(f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "    # Convertendo rótulos e probabilidades para NumPy\n",
        "    val_labels = np.array(val_labels)\n",
        "    val_probabilities = np.array(val_probabilities)\n",
        "\n",
        "    # Gerar e plotar a curva Precision-Recall para cada classe (one-vs-rest)\n",
        "    for class_idx in range(num_classes):  # Para cada classe (0, 1 e 2)\n",
        "        precision, recall, _ = precision_recall_curve(val_labels == class_idx, val_probabilities[:, class_idx])\n",
        "        average_precision = average_precision_score(val_labels == class_idx, val_probabilities[:, class_idx])\n",
        "\n",
        "        plt.figure(figsize=(4, 2))\n",
        "        plt.plot(recall, precision, label=f'AP = {average_precision:.2f}')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title(f'Precision-Recall Curve - Epoch {epoch + 1} - Classe {class_idx}')\n",
        "        plt.legend(loc='best')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "8dewWv-zjMte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pginApXvL6q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar as métricas\n",
        "plt.figure(figsize=(4, 2))\n",
        "\n",
        "\n",
        "# Plot precisão\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_precisions, label='Precisão de Treinamento')\n",
        "plt.plot(val_precisions, label='Precisão de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisão')\n",
        "plt.legend()\n",
        "plt.title('Precisão ao Longo das Épocas')\n",
        "\n",
        "# Plot F1-score\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_f1s, label='F1-Score de Treinamento')\n",
        "plt.plot(val_f1s, label='F1-Score de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.legend()\n",
        "plt.title('F1-Score ao Longo das Épocas')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oyg87oWnCwNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Avaliação\n",
        "model.eval()\n",
        "val_preds = []\n",
        "val_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in eval_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['sentiment'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "        val_preds.extend(preds)\n",
        "        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "conf_matrix = confusion_matrix(val_labels, val_preds)\n",
        "\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "oA6PRFxAuJp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar a matriz de confusão\n",
        "plt.figure(figsize=(4, 2))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['negativo', 'neutro', 'positivo'], yticklabels=['negativo', 'neutro', 'positivo'])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XKUEdFAJuTan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j1Ff5Lsaqokn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o modelo treinado\n",
        "model.save_pretrained('caminho_para_salvar_o_modelo')\n",
        "tokenizer.save_pretrained('caminho_para_salvar_o_tokenizer')\n"
      ],
      "metadata": {
        "id": "cGV6CPvwJF_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "segunda op."
      ],
      "metadata": {
        "id": "1iINHKPOfvf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do ambiente de treinamento, permitindo o controle sobre o processo de otimização, salvamento de modelos e avaliação, garantindo o monitoraramento do desempenho ao longo do tempo."
      ],
      "metadata": {
        "id": "VAdnyxPSTPUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criar o Trainer\n",
        "\n",
        "configura e inicia o treinamento do modelo BERT para classificação de sentimentos usando a biblioteca transformers\n"
      ],
      "metadata": {
        "id": "daTW-BwKpw_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# métricas de desempenho do modelo no conjunto de dados de **avaliação**"
      ],
      "metadata": {
        "id": "rPZn8AY-5eMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AVALIAÇÃO"
      ],
      "metadata": {
        "id": "nkyoFe5hkZ_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Barras para a Distribuição de Sentimentos"
      ],
      "metadata": {
        "id": "7ZizTaaLGZAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supondo que a coluna 'label' contém 0 (Negativo), 1 (Positivo), e 2 (Neutro)\n",
        "sentiment_counts = df_concatenado['sentiment'].value_counts()\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.figure(figsize=(4,2))\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n",
        "plt.title('Distribuição de Sentimentos')\n",
        "plt.xlabel('Sentimento')\n",
        "plt.ylabel('Quantidade de Textos')\n",
        "plt.xticks(ticks=[0, 1, 2], labels=['Negativo', 'Positivo', 'Neutro'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KYlBE0XZGYXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de Linha para Evolução Temporal dos Sentimentos\n"
      ],
      "metadata": {
        "id": "cTpVetTVGeF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuvem de Palavras"
      ],
      "metadata": {
        "id": "1UXoK3eoGhct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a distribuição dos rótulos\n",
        "print(df_concatenado['sentiment'].value_counts())\n"
      ],
      "metadata": {
        "id": "V_GDflJkaqjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusão\n"
      ],
      "metadata": {
        "id": "vhnx3JbGGlOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter a coluna de data para datetime, se ainda não foi feito\n",
        "df_concatenado['created_at'] = pd.to_datetime(df_concatenado['created_at'])\n",
        "\n",
        "# Agrupar os sentimentos por data\n",
        "sentiment_over_time = df_concatenado.groupby([df_concatenado['created_at'].dt.date, 'sentiment']).size().unstack(fill_value=0)\n",
        "\n",
        "# Visualizar os resultados\n",
        "sentiment_over_time.plot(kind='line', figsize=(10, 6))\n",
        "plt.title('Sentimentos ao Longo do Tempo nas Eleições')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Número de Sentimentos')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_XqxGYj9rTd3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}